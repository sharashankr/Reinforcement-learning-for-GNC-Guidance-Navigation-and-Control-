{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "af7aaaea8c2b14deb2496c07f500f616",
          "grade": false,
          "grade_id": "cell-b37957442e1fbd8b",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "SvHoPfJyGtf6"
      },
      "source": [
        "# Objective\n",
        "\n",
        "In this notebook, we will conduct a careful experiment analyzing performance of an agent, under different values of the step-size parameter.\n",
        "\n",
        "**In this notebook, we will:**\n",
        "\n",
        "- write a script to run your agent and environment on a set of parameters, to determine performance across these parameters.\n",
        "- gain insight into the impact of the step-size parameter on agent performance by examining its parameter sensitivity curve."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_sIFBdbOlWGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "619bb4ae4c61f3c5d28bab13a2deaea5",
          "grade": false,
          "grade_id": "cell-9b62cd317dfd157f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "XClky8t1Gtf9"
      },
      "source": [
        "## Packages\n",
        "\n",
        "- [numpy](www.numpy.org) : Fundamental package for scientific computing with Python.\n",
        "- [matplotlib](http://matplotlib.org) : Library for plotting graphs in Python.\n",
        "- [RL-Glue](http://www.jmlr.org/papers/v10/tanner09a.html) : Library for reinforcement learning experiments.\n",
        "- [tqdm](https://tqdm.github.io/) : A package to display progress bar when running experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "7bfa3a156b7eaccdbd19dc9bdad0efc3",
          "grade": false,
          "grade_id": "cell-b48b54531e30224f",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "teX1aFlEGtf-"
      },
      "outputs": [],
      "source": [
        "# Do not modify this cell!\n",
        "\n",
        "# Import necessary libraries\n",
        "# DO NOT IMPORT OTHER LIBRARIES - This will break the autograder.\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from rl_glue import RLGlue\n",
        "from environment import BaseEnvironment\n",
        "from agent import BaseAgent\n",
        "from dummy_environment import DummyEnvironment\n",
        "from dummy_agent import DummyAgent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "29e149431bdee8567eaa8b98232f4e14",
          "grade": false,
          "grade_id": "cell-f8442d4f392c0918",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "3hyTkzwBGtf_"
      },
      "source": [
        "## Section 1: Write Parameter Study Script\n",
        "\n",
        "In this section, we will write a script for performing parameter studies. We will implement the `run_experiment()` function. This function takes an environment and agent and performs a parameter study on the step-size and termperature parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "7aeae683dd5fd3bcfc7fa066b233a974",
          "grade": false,
          "grade_id": "cell-2a279281a516eb2c",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "6056_G2cGtgA"
      },
      "outputs": [],
      "source": [
        "#GRADED FUNCTION: [parameter study]\n",
        "\n",
        "def run_experiment(environment, agent, environment_parameters, agent_parameters, experiment_parameters):\n",
        "\n",
        "    \"\"\"\n",
        "    Assume environment_parameters dict contains:\n",
        "    {\n",
        "        input_dim: integer,\n",
        "        num_actions: integer,\n",
        "        discount_factor: float\n",
        "    }\n",
        "\n",
        "    Assume agent_parameters dict contains:\n",
        "    {\n",
        "        step_size: 1D numpy array of floats,\n",
        "        tau: 1D numpy array of floats\n",
        "    }\n",
        "\n",
        "    Assume experiment_parameters dict contains:\n",
        "    {\n",
        "        num_runs: integer,\n",
        "        num_episodes: integer\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    ### Instantiate rl_glue from RLGlue\n",
        "    rl_glue = RLGlue(environment, agent)\n",
        "\n",
        "    os.system('sleep 1') # to prevent tqdm printing out-of-order\n",
        "\n",
        "    ### START CODE HERE\n",
        "\n",
        "     ### Initialize agent_sum_reward to zero in the form of a numpy array\n",
        "    # with shape (number of values for tau, number of step-sizes, number of runs, number of episodes)\n",
        "    agent_sum_reward = np.zeros((len(agent_parameters[\"tau\"]), len(agent_parameters[\"step_size\"]), experiment_parameters[\"num_runs\"], experiment_parameters[\"num_episodes\"]))\n",
        "\n",
        "    ### Replace the Nones with the correct values in the rest of the code\n",
        "\n",
        "    # for loop over different values of tau\n",
        "    # tqdm is used to show a progress bar for completing the parameter study\n",
        "    for i in tqdm(range(len(agent_parameters[\"tau\"]))):\n",
        "\n",
        "        # for loop over different values of the step-size\n",
        "        for j in range(len(agent_parameters[\"step_size\"])):\n",
        "\n",
        "            ### Specify env_info\n",
        "            env_info = {}\n",
        "\n",
        "            ### Specify agent_info\n",
        "            agent_info = {\"num_actions\": environment_parameters[\"num_actions\"],\n",
        "                          \"input_dim\": environment_parameters[\"input_dim\"],\n",
        "                          \"discount_factor\": environment_parameters[\"discount_factor\"],\n",
        "                          \"tau\": agent_parameters[\"tau\"][i],\n",
        "                          \"step_size\": agent_parameters[\"step_size\"][j]}\n",
        "\n",
        "            # for loop over runs\n",
        "            for run in range(experiment_parameters[\"num_runs\"]):\n",
        "\n",
        "                # Set the seed\n",
        "                agent_info[\"seed\"] = agent_parameters[\"seed\"] * experiment_parameters[\"num_runs\"] + run\n",
        "\n",
        "                # Beginning of the run\n",
        "                rl_glue.rl_init(agent_info, env_info)\n",
        "\n",
        "                for episode in range(experiment_parameters[\"num_episodes\"]):\n",
        "\n",
        "                    # Run episode\n",
        "                    rl_glue.rl_episode(0) # no step limit\n",
        "\n",
        "                    ### Store sum of reward\n",
        "                    agent_sum_reward[i, j, run, episode] = rl_glue.rl_agent_message(\"get_sum_reward\")\n",
        "\n",
        "            if not os.path.exists('results'):\n",
        "                    os.makedirs('results')\n",
        "\n",
        "            save_name = \"{}\".format(rl_glue.agent.name).replace('.','')\n",
        "\n",
        "            # save sum reward\n",
        "            np.save(\"results/sum_reward_{}\".format(save_name), agent_sum_reward)\n",
        "\n",
        "    ### END CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "df5e20c532d780d5353f044cefabda89",
          "grade": false,
          "grade_id": "cell-bca56669ed9bbce9",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "8b0yksMUGtgB"
      },
      "source": [
        "Following code will test our implementation of `run_experiment()` given a dummy agent and a dummy environment for 100 runs, 100 episodes, 12 values of the step-size, and 4 values of $\\tau$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "4a6868062d024122787399fe9029e494",
          "grade": true,
          "grade_id": "cell-56541717f4f15d20",
          "locked": true,
          "points": 100,
          "schema_version": 1,
          "solution": false
        },
        "id": "X9LZnlhHGtgB",
        "outputId": "cea45f37-98a2-470d-f0bc-8697d341a21d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:11<00:00,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Passed the assert!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Experiment parameters\n",
        "experiment_parameters = {\n",
        "    \"num_runs\" : 100,\n",
        "    \"num_episodes\" : 100,\n",
        "}\n",
        "\n",
        "# Environment parameters\n",
        "environment_parameters = {\n",
        "    \"input_dim\" : 8,\n",
        "    \"num_actions\": 4,\n",
        "    \"discount_factor\" : 0.99\n",
        "}\n",
        "\n",
        "agent_parameters = {\n",
        "    \"step_size\": 3e-5 * np.power(2.0, np.array([-6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5])),\n",
        "    \"tau\": np.array([0.001, 0.01, 0.1, 1.0]),\n",
        "    \"seed\": 0\n",
        "}\n",
        "\n",
        "test_env = DummyEnvironment\n",
        "test_agent = DummyAgent\n",
        "\n",
        "run_experiment(test_env,\n",
        "               test_agent,\n",
        "               environment_parameters,\n",
        "               agent_parameters,\n",
        "               experiment_parameters)\n",
        "\n",
        "sum_reward_dummy_agent = np.load(\"results/sum_reward_dummy_agent.npy\")\n",
        "sum_reward_dummy_agent_answer = np.load(\"asserts/sum_reward_dummy_agent.npy\")\n",
        "assert(np.allclose(sum_reward_dummy_agent, sum_reward_dummy_agent_answer))\n",
        "\n",
        "print(\"Passed the assert!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "00c09538f65dff6afe75f359870f5126",
          "grade": false,
          "grade_id": "cell-bea11a6380a836e3",
          "locked": true,
          "schema_version": 1,
          "solution": false
        },
        "id": "qT5skalUGtgD"
      },
      "source": [
        "## Section 2: The Parameter Study for the Agent with Neural Network and Adam Optimizer\n",
        "\n",
        "Now that we have implemented `run_experiment()` for a dummy agent, let’s examine the performance of the agent we implemented earlier for different values of the step-size parameter. To do so, we can use parameter sensitivity curves. As we know, in parameter sensitivity curves, on the y-axis, we have our performance measure and on the x-axis, we have the values of the parameter we are testing. We will use the average of returns over episodes, averaged over 30 runs, as our performance metric.\n",
        "\n",
        "Recall that we used a step-size of \\(10^{-3}\\) in Assignment 2 and obtained reasonable performance. We can use this value to construct a sensible set of step-sizes for our parameter study by multiplying it with powers of two:\n",
        "\n",
        "\\[\n",
        "10^{-3} \\times 2^x \\quad \\text{where} \\quad x \\in \\{-9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3\\}\n",
        "\\]\n",
        "\n",
        "We use powers of two because doing so produces smaller increments in the step-size for smaller values and larger jumps for larger step-sizes.\n",
        "\n",
        "Let’s take a look at the results for this set of step-sizes.\n",
        "\n",
        "![Parameter Study Results](parameter_study.png)\n",
        "\n",
        "Observe that the best performance is achieved for step-sizes in the range \\([10^{-4}, 10^{-3}]\\). This includes the step-size we used in the previous step. The performance degrades for higher and lower step-size values. Since the range of step-sizes for which the agent performs well is not broad, choosing a good step-size is challenging for this problem.\n",
        "\n",
        "As mentioned above, we used the average of returns over episodes, averaged over 30 runs, as our performance metric. This metric gives an overall estimation of the agent's performance over the episodes. If we want to study the effect of the step-size parameter on the agent's early or final performance, we should use different metrics. For example, to study the effect of the step-size parameter on early performance, we could use the average of returns over the first 100 episodes, averaged over 30 runs. When conducting a parameter study, we may consider these for defining our performance metric!"
      ]
    }
  ],
  "metadata": {
    "coursera": {
      "course_slug": "complete-reinforcement-learning-system",
      "graded_item_id": "h4ZLq",
      "launcher_item_id": "rbt6a"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}